{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1tyOsGoLGnyG0m4Quy9utjh-UMHxZ68_C",
      "authorship_tag": "ABX9TyMNFO9Qx5OZFFK/j4rFEZfk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZohairKanani/UROP_sample/blob/main/UROP_Sample_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btwAg__zxfSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q5ppLoGU8tFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5SySvSWIN-Kn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "yd9B2jTW0f7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9995faa9-f02e-41d2-9dd9-538a5fef3fb6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "UmMc9Ab7L2xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fbf7b4bc-67a5-418e-d3e0-0158b1651e52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "2-Jy_QW7hmtK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize the images to 64x64\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])"
      ],
      "metadata": {
        "id": "wpRTYU3jhxvI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create dataset(s)\n",
        "from torchvision import datasets\n",
        "from pathlib import Path\n",
        "data_dir = Path(\"data\")\n",
        "train_data = datasets.Food101(root=data_dir,\n",
        "                              split = \"train\",# target folder of images\n",
        "                              transform=data_transform, # transforms to perform on data (images)\n",
        "                              download = True) # transforms to perform on labels (if necessary)\n",
        "\n",
        "test_data = datasets.Food101(root=data_dir,\n",
        "                              split = \"test\",# target folder of images\n",
        "                              transform=data_transform, # transforms to perform on data (images)\n",
        "                              download = True) # transforms to perform on labels (if necessary)\n",
        "\n",
        "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFzGp5re-BTt",
        "outputId": "13912fb7-32c6-41b4-957a-352e21ebe10d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to data/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4996278331/4996278331 [03:30<00:00, 23680760.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/food-101.tar.gz to data\n",
            "Train data:\n",
            "Dataset Food101\n",
            "    Number of datapoints: 75750\n",
            "    Root location: data\n",
            "    split=train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n",
            "Test data:\n",
            "Dataset Food101\n",
            "    Number of datapoints: 25250\n",
            "    Root location: data\n",
            "    split=test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
            "               RandomHorizontalFlip(p=0.5)\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJRMggJJ_9bC",
        "outputId": "c7468798-aba3-4521-a141-cd1f2cd0be0b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple_pie',\n",
              " 'baby_back_ribs',\n",
              " 'baklava',\n",
              " 'beef_carpaccio',\n",
              " 'beef_tartare',\n",
              " 'beet_salad',\n",
              " 'beignets',\n",
              " 'bibimbap',\n",
              " 'bread_pudding',\n",
              " 'breakfast_burrito',\n",
              " 'bruschetta',\n",
              " 'caesar_salad',\n",
              " 'cannoli',\n",
              " 'caprese_salad',\n",
              " 'carrot_cake',\n",
              " 'ceviche',\n",
              " 'cheese_plate',\n",
              " 'cheesecake',\n",
              " 'chicken_curry',\n",
              " 'chicken_quesadilla',\n",
              " 'chicken_wings',\n",
              " 'chocolate_cake',\n",
              " 'chocolate_mousse',\n",
              " 'churros',\n",
              " 'clam_chowder',\n",
              " 'club_sandwich',\n",
              " 'crab_cakes',\n",
              " 'creme_brulee',\n",
              " 'croque_madame',\n",
              " 'cup_cakes',\n",
              " 'deviled_eggs',\n",
              " 'donuts',\n",
              " 'dumplings',\n",
              " 'edamame',\n",
              " 'eggs_benedict',\n",
              " 'escargots',\n",
              " 'falafel',\n",
              " 'filet_mignon',\n",
              " 'fish_and_chips',\n",
              " 'foie_gras',\n",
              " 'french_fries',\n",
              " 'french_onion_soup',\n",
              " 'french_toast',\n",
              " 'fried_calamari',\n",
              " 'fried_rice',\n",
              " 'frozen_yogurt',\n",
              " 'garlic_bread',\n",
              " 'gnocchi',\n",
              " 'greek_salad',\n",
              " 'grilled_cheese_sandwich',\n",
              " 'grilled_salmon',\n",
              " 'guacamole',\n",
              " 'gyoza',\n",
              " 'hamburger',\n",
              " 'hot_and_sour_soup',\n",
              " 'hot_dog',\n",
              " 'huevos_rancheros',\n",
              " 'hummus',\n",
              " 'ice_cream',\n",
              " 'lasagna',\n",
              " 'lobster_bisque',\n",
              " 'lobster_roll_sandwich',\n",
              " 'macaroni_and_cheese',\n",
              " 'macarons',\n",
              " 'miso_soup',\n",
              " 'mussels',\n",
              " 'nachos',\n",
              " 'omelette',\n",
              " 'onion_rings',\n",
              " 'oysters',\n",
              " 'pad_thai',\n",
              " 'paella',\n",
              " 'pancakes',\n",
              " 'panna_cotta',\n",
              " 'peking_duck',\n",
              " 'pho',\n",
              " 'pizza',\n",
              " 'pork_chop',\n",
              " 'poutine',\n",
              " 'prime_rib',\n",
              " 'pulled_pork_sandwich',\n",
              " 'ramen',\n",
              " 'ravioli',\n",
              " 'red_velvet_cake',\n",
              " 'risotto',\n",
              " 'samosa',\n",
              " 'sashimi',\n",
              " 'scallops',\n",
              " 'seaweed_salad',\n",
              " 'shrimp_and_grits',\n",
              " 'spaghetti_bolognese',\n",
              " 'spaghetti_carbonara',\n",
              " 'spring_rolls',\n",
              " 'steak',\n",
              " 'strawberry_shortcake',\n",
              " 'sushi',\n",
              " 'tacos',\n",
              " 'takoyaki',\n",
              " 'tiramisu',\n",
              " 'tuna_tartare',\n",
              " 'waffles']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViHnMcOWIxkv",
        "outputId": "0d82e34d-1357-4b9c-a7a3-f3733a8deea9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'apple_pie': 0,\n",
              " 'baby_back_ribs': 1,\n",
              " 'baklava': 2,\n",
              " 'beef_carpaccio': 3,\n",
              " 'beef_tartare': 4,\n",
              " 'beet_salad': 5,\n",
              " 'beignets': 6,\n",
              " 'bibimbap': 7,\n",
              " 'bread_pudding': 8,\n",
              " 'breakfast_burrito': 9,\n",
              " 'bruschetta': 10,\n",
              " 'caesar_salad': 11,\n",
              " 'cannoli': 12,\n",
              " 'caprese_salad': 13,\n",
              " 'carrot_cake': 14,\n",
              " 'ceviche': 15,\n",
              " 'cheese_plate': 16,\n",
              " 'cheesecake': 17,\n",
              " 'chicken_curry': 18,\n",
              " 'chicken_quesadilla': 19,\n",
              " 'chicken_wings': 20,\n",
              " 'chocolate_cake': 21,\n",
              " 'chocolate_mousse': 22,\n",
              " 'churros': 23,\n",
              " 'clam_chowder': 24,\n",
              " 'club_sandwich': 25,\n",
              " 'crab_cakes': 26,\n",
              " 'creme_brulee': 27,\n",
              " 'croque_madame': 28,\n",
              " 'cup_cakes': 29,\n",
              " 'deviled_eggs': 30,\n",
              " 'donuts': 31,\n",
              " 'dumplings': 32,\n",
              " 'edamame': 33,\n",
              " 'eggs_benedict': 34,\n",
              " 'escargots': 35,\n",
              " 'falafel': 36,\n",
              " 'filet_mignon': 37,\n",
              " 'fish_and_chips': 38,\n",
              " 'foie_gras': 39,\n",
              " 'french_fries': 40,\n",
              " 'french_onion_soup': 41,\n",
              " 'french_toast': 42,\n",
              " 'fried_calamari': 43,\n",
              " 'fried_rice': 44,\n",
              " 'frozen_yogurt': 45,\n",
              " 'garlic_bread': 46,\n",
              " 'gnocchi': 47,\n",
              " 'greek_salad': 48,\n",
              " 'grilled_cheese_sandwich': 49,\n",
              " 'grilled_salmon': 50,\n",
              " 'guacamole': 51,\n",
              " 'gyoza': 52,\n",
              " 'hamburger': 53,\n",
              " 'hot_and_sour_soup': 54,\n",
              " 'hot_dog': 55,\n",
              " 'huevos_rancheros': 56,\n",
              " 'hummus': 57,\n",
              " 'ice_cream': 58,\n",
              " 'lasagna': 59,\n",
              " 'lobster_bisque': 60,\n",
              " 'lobster_roll_sandwich': 61,\n",
              " 'macaroni_and_cheese': 62,\n",
              " 'macarons': 63,\n",
              " 'miso_soup': 64,\n",
              " 'mussels': 65,\n",
              " 'nachos': 66,\n",
              " 'omelette': 67,\n",
              " 'onion_rings': 68,\n",
              " 'oysters': 69,\n",
              " 'pad_thai': 70,\n",
              " 'paella': 71,\n",
              " 'pancakes': 72,\n",
              " 'panna_cotta': 73,\n",
              " 'peking_duck': 74,\n",
              " 'pho': 75,\n",
              " 'pizza': 76,\n",
              " 'pork_chop': 77,\n",
              " 'poutine': 78,\n",
              " 'prime_rib': 79,\n",
              " 'pulled_pork_sandwich': 80,\n",
              " 'ramen': 81,\n",
              " 'ravioli': 82,\n",
              " 'red_velvet_cake': 83,\n",
              " 'risotto': 84,\n",
              " 'samosa': 85,\n",
              " 'sashimi': 86,\n",
              " 'scallops': 87,\n",
              " 'seaweed_salad': 88,\n",
              " 'shrimp_and_grits': 89,\n",
              " 'spaghetti_bolognese': 90,\n",
              " 'spaghetti_carbonara': 91,\n",
              " 'spring_rolls': 92,\n",
              " 'steak': 93,\n",
              " 'strawberry_shortcake': 94,\n",
              " 'sushi': 95,\n",
              " 'tacos': 96,\n",
              " 'takoyaki': 97,\n",
              " 'tiramisu': 98,\n",
              " 'tuna_tartare': 99,\n",
              " 'waffles': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K92QPPhIUDUU",
        "outputId": "7efc4719-f404-4efb-ba69-abd3030d6cbc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75750, 25250)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image tensor:\\n{img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rackYGVUUGzv",
        "outputId": "a50b15df-81bb-4065-c2aa-01d34a547908"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image tensor:\n",
            "tensor([[[0.9725, 0.9725, 0.9765,  ..., 0.4745, 0.3765, 0.3843],\n",
            "         [0.9765, 0.9765, 0.9725,  ..., 0.4980, 0.3882, 0.4157],\n",
            "         [0.9725, 0.9725, 0.9765,  ..., 0.5490, 0.4902, 0.4588],\n",
            "         ...,\n",
            "         [0.6314, 0.6627, 0.6392,  ..., 0.6118, 0.4980, 0.4824],\n",
            "         [0.6235, 0.6314, 0.6235,  ..., 0.5059, 0.4980, 0.5098],\n",
            "         [0.5922, 0.5961, 0.6118,  ..., 0.5020, 0.5294, 0.5608]],\n",
            "\n",
            "        [[0.9569, 0.9490, 0.9569,  ..., 0.1882, 0.1373, 0.1490],\n",
            "         [0.9569, 0.9529, 0.9529,  ..., 0.2078, 0.1451, 0.1647],\n",
            "         [0.9529, 0.9529, 0.9569,  ..., 0.2314, 0.2039, 0.1765],\n",
            "         ...,\n",
            "         [0.3137, 0.3451, 0.3216,  ..., 0.5529, 0.4235, 0.4078],\n",
            "         [0.3098, 0.3176, 0.3059,  ..., 0.4431, 0.4275, 0.4510],\n",
            "         [0.2902, 0.2941, 0.2941,  ..., 0.4510, 0.4667, 0.5098]],\n",
            "\n",
            "        [[0.9608, 0.9569, 0.9529,  ..., 0.1137, 0.0824, 0.0863],\n",
            "         [0.9608, 0.9569, 0.9529,  ..., 0.0980, 0.0667, 0.0863],\n",
            "         [0.9529, 0.9529, 0.9529,  ..., 0.1020, 0.0863, 0.0745],\n",
            "         ...,\n",
            "         [0.0667, 0.0863, 0.0745,  ..., 0.4902, 0.3686, 0.3529],\n",
            "         [0.0706, 0.0706, 0.0706,  ..., 0.3765, 0.3647, 0.3882],\n",
            "         [0.0588, 0.0667, 0.0706,  ..., 0.3765, 0.4039, 0.4510]]])\n",
            "Image shape: torch.Size([3, 64, 64])\n",
            "Image datatype: torch.float32\n",
            "Image label: 23\n",
            "Label datatype: <class 'int'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test Datasets into DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=1, # how many samples per batch?\n",
        "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
        "                              shuffle=True) # shuffle the data?\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False) # don't usually need to shuffle testing data\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLOLjmXzUu3J",
        "outputId": "1f3f9023-3e16-4494-cbd8-1faf8a739609"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7d33fa3e7c70>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7d33fa3e4e50>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoX6U5gZVcE0",
        "outputId": "d6180c31-29d1-41a3-fffe-05c7aa810d8d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: torch.Size([1, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
            "Label shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Dict, List\n",
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    \"\"\"Finds the class folder names in a target directory.\n",
        "\n",
        "    Assumes target directory is in standard image classification format.\n",
        "\n",
        "    Args:\n",
        "        directory (str): target directory to load classnames from.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
        "\n",
        "    Example:\n",
        "        find_classes(\"food_images/train\")\n",
        "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
        "    \"\"\"\n",
        "    # 1. Get the class names by scanning the target directory\n",
        "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "    # 2. Raise an error if class names not found\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
        "\n",
        "    # 3. Crearte a dictionary of index labels (computers prefer numerical rather than string labels)\n",
        "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
        "    return classes, class_to_idx"
      ],
      "metadata": {
        "id": "kiXTPQNCVe3V"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "import os"
      ],
      "metadata": {
        "id": "JjlQzA_6CbYJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the final classification layer\n",
        "for name, param in model.named_parameters():\n",
        "    if \"fc\" in name:  # Unfreeze the final classification layer\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Use all parameters\n",
        "\n",
        "\n",
        "# Move the model to the GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "SBLIoV-sCNQA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_sizes = {\"train\": len(train_data),\"test\": len(test_data)}\n",
        "#dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "dataset_sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t0-hQgMFRpg",
        "outputId": "6a4c4ca1-1fb4-4a19-db79-9e4321c00eb9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': 75750, 'test': 25250}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for phase in ['train', 'test']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "            dataloader = train_dataloader\n",
        "        else:\n",
        "            model.eval()\n",
        "            dataloader = test_dataloader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "Clq2YKxgCmOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505b996a-3bd0-494d-b5ad-2d88154e6f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 5.7001 Acc: 0.0116\n",
            "test Loss: 62.4683 Acc: 0.0085\n",
            "train Loss: 5.6585 Acc: 0.0121\n",
            "test Loss: 64.4531 Acc: 0.0082\n",
            "train Loss: 5.6239 Acc: 0.0129\n",
            "test Loss: 104.0759 Acc: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbSI8O6pWNOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTasp-s_WYJR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}